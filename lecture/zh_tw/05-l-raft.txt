6.824 2017 Lecture 5: Raft (1)

為何要讀這篇論文?
  分散共識(distributed consensus) 是個研究數十年的難題
  Lab 2 與 Lab 3 都是基於 Raft

這堂課
  今天: Raft 選舉與 log 處理(Lab 2A, 2B)
  下堂: Raft 持久層, 客戶端行為, 快照(snapshop) (Lab 2C, Lab 3)

概觀主題: 使用 replicated state machines(RSM) 建立可容錯的服務
  [客戶端, 複數複本伺服器]
  範例: configuration 伺服器, 如 MapResuce 或 GFS master
  範例: key/value 儲存伺服器, put()/get() (lab 3)
  目標: 客戶端看到的行為，如同單一個非複本伺服器
    不管有幾台失效的伺服器，服務都可用
  策略:
    每個複本伺服器以相同順序執行相同命令
    執行過程中保持複本(i.e. 完全相同)
    如果一個失效，其他複本可以補上
    i.e. 如果失效，客戶端切換到其他伺服器
  GFS 與 VM-FT 都是這樣

一個核心問題: 如何避免多頭馬車(split brain)?
  假設客戶端可連線 replica A 但不能連 replica B
  客戶端可以只用 replica A 繼續工作嗎?
  如果 B 確實失效, 客戶必須在沒有 B 的情形下工作
    不然服務就無法容錯
  如果 B 沒有失效, 但是網路造成客戶無法連上 B
    也許客戶不應該沒有 B 還繼續工作
    B 可能會服務其他的客戶端 -- 造成多頭馬車

範例: 為何多頭馬車不被允許
  容錯的 key/value 資料庫
  C1 與 C2 分開在不同的網路分割，各自向不同的伺服器連線
  C1: put("k1", "v1")
  C2: put("K1", "v2")
  C1: get("k1") -> ???
  正確的答案是 "v2"，如同是單一分複本伺服器
  但如果兩個伺服器，因為網路分割獨立的服務 C1 與 C2
    C1 get("k1") 會獲得 "v1"

問題: 機器無法判別究竟是機器故障，還是網路分割
  兩者的現象都是無法與其他機器溝通

我們想要一個 state machine replication scheme 能夠符合三個目標:
  1. 有任何 fail-stop 失效，仍然保持可用
  2. 不論有無多頭馬車，都能處理分割
  3. 如果太多失效發生，則等待機器復原，然後才繼續工作

處理分割問題的一個想法: 多數決(majority vote)
  2f+1 個伺服器可容忍 f 個失效，e.g. 3 伺服器可以承受 1 台失效
  每個步驟，都需要讓多數的(f+1) 個伺服器取得共識
    f 台伺服器失效，剩下 f+1 台取得多數，所以仍然可以工作
  多數決如何比面多頭馬車?
    最多只會有一個分割取得多數(f, f+1, f+1 取得多數共識，f 分割則無法取得多數)
  note: 多數決的門檻是對所有 2f+1 台機器，而不是指計算活著的機器
  多數決很有用的一點，是任何兩台機器都需要交會(instersection)
    兩台交會的伺服器只會投票給兩者其中之一
    透過交會，可以傳遞剛剛兩台取得的決定

兩個容忍分割（partition-tolerant）的複本設計在 1990 發明
  Paxos 與 View-Stamped Replication
  過去十年這個技術使用在許多現實案例
  Raft 論文則是導入了現代科技

*** 主題: Raft 概論

Raft 的 state machine replication -- Lab 3 為例
  [流程圖: 客戶端, 3 複本, k/v 層, raft 層, logs]
  伺服器的 Raft 層選出一個 leader
  客戶端送 RPCs 到 leader 的 k/v 層
    Put, Get, Append
  k/v 層轉發要求到 Raft 層，暫時不回覆客戶端
  leader 的 Raft 層傳送客戶端的命令到所有複本
    透過 AppendEntries RPCs
    每個 follower append log 到本地的 log（但尚未commit)
    回覆 leader acknowledge
  如果多數複本都 append log，master 上的 log 狀態變成 commited
    commited 確保 log 不會遺失
    維持多數 -> 就算發生新的 leader 選舉，log 也一定存在 master
  直到 leader 確認 commited，複本伺服器才會應用該 log 的變更
    複本透過下一次的 AppendEntries RPC 發現（透過 commitIndex）
  commited 後，leader 回覆 k/v 層
    k/v 層應用 Put 到 DB 中，或是取得 Get 的結果
  leader 回覆 client 執行命令的結果

為何使用 log?
  服務會保留 state machine state, e.g. key/value DB
    為何這樣還不夠?
  幫每個指令編號很重要
    幫助複本們同意一次執行的順序
    幫助 leader 確保 followers 都有完全相同的 log
  複本們也使用 log 來儲存指令
    直到 leader commit 指令
    如果 follower 遺失指令，leader 會重送
    就算下次重啟，也可維持持久層的資料

Raft 的設計有量個主要的部份
  選出新的 leader
  就算有錯誤，也確保完全相同的 log

*** 主題: leader 選舉(lLab 2A)

為何使用單一 leader?
  確保每個複本都依照相同順序，執行相同命令

Raft 使用"任期"(terms) 來標注一段一段不同 leader 的時期
  每個新 leader -> 新的任期
  每個任期最多一個 leader，可能會沒有 leader
  每次選舉都連結到一個特定的任期
    一個任期只會有一次成功選出 leader 的選舉
  任期的記數幫助伺服器跟隨正確的 leader，而不是卸任的 leader

Raft 何時開啟一論新的選舉?
  AppendEntries 作為心跳連結(heartbeats)，leader 會週期性的傳送
  如果伺服器沒有收到當前 leader 的 AppendEntry，經過一段"選舉超時"的時間(election timeout) 後
    伺服器會認為 leader 已經失效，並自己開始新的一輪選舉
  [狀態轉移流程圖, Figure 4: follower, candidate, leader]
  followers 遞增(increment) 本地的 currentTerm, 自己當作候選人(candidate)並開始選舉
  note: 這可能導致沒有必要的選舉發生，可能會降低效能，但能確保安全
  note: 舊的 leader 可能仍正常工作，並覺得自己仍是 leader

一個伺服器變成候選人後會發生什麼事？
  三個可能：
    1) 取得多數決，成為 leader
      觀察投票與計票都發生在伺服器本地
      note：無法避免拜占庭錯誤（byzantine faults)
    2) 無法取得多數，但聽到另一個 leader 成功先取得多數
      透過新 leader 的 AppendEntries RPC
      伺服器跟隨另一個 leader 的權威，成為 follower
    3) 無法取得多數，但也沒有收到新 leader 的訊息
      e.g. 如果伺服器網路分割到少數群
      選舉逾時（timeout）並開始新的一輪選舉，繼續當候選人
  note：案例 3)中，有可能會陷入一直遞增選舉
    但無法影響 log，因為被分割在少數群，無法成為 leader
    當網路分割修復後，任期數較高的選舉確保有效性
    but：一個情形是多數群中的 log 比較長（才會拒絕較高任期的候選人）
      不然就是兩個群機器的 log 都一樣長，多數群的分割就會維持現狀（較高任期的候選人贏得選舉，沒有造成 log 損失）

如何確保每個任期至多只有一個 leader
  [Figure 2 RequestVote RPC 與伺服器的規則]
  leader 必須從多數節點中取得"yes"
  給個節點一個任期只能投票一次
  每個任期最多一個節點能夠取得多數
    -> 就算有網路分割，最多也是一個 leader
    -> 就算有多台節點失效，選舉仍能夠成功

一個新的 leader 如何自行確立（self-establish）
  選舉勝者取得多數"yes"
  立刻發送 AppendEntries RPC （心跳連結）給每個節點
    心跳連結會壓制其他節點發起新的選舉

一個選舉不成功有兩個原因：
  可連結的節點數量不足多數
  同時多個候選人分散選票，彼此都無法取得多數決

選舉不成功後發生什麼事?
  節點等待心跳連結逾時，自行發起另一輪選舉
  較高任期（的選舉）有優先權，舊任期的候選人（收到新任期的選舉後）會退選舊任期  

如何設定選舉的逾時期限？
  每個節點選擇一個隨機的逾時期限
    這可以避免多個候選人同時參選分散選票
  隨機可以打破節點間的對稱性（symmetry）
    節點會選擇最短的延遲
    避免所有節點各自同時發起新的選舉，然後只投給自己
  希望在選舉逾期前有足夠時間（取得多數）
  其他節點收到新 leader 的 ApendEntries 心跳連結後
    就不會變成候選人
  應該選擇什麼數值？
    至少大於幾個心跳連結的間距（以免網路遺失，或是延後一次心跳）
    隨機的部份又要夠長，才有足夠時間在下一輪選舉發生前，完成本輪選舉
    但又要夠短，以便測試方失去耐心前做幾次測試
      測試方要求選舉在 5 秒以內完成

*** 主題：Raft log (Lab 2B)

我們談過 leader 如何複製 log 紀錄
  重要的區別：複製的 log 與 committed 的 log
    commited 的紀錄保證永遠不會遺失
    複製但沒有 commit 的紀錄有可能會被複寫
  幫助思考每個參與者的明確 "commit frontier"

節點上的 log 能否與其他節點的複本完全相同
  no：有些複本會延遲
  no：待會會介紹 log 暫時性的紀錄偏差
  好消息：
    （不同的複本）終究會收斂
    commit 機制確保節點只執行穩定的紀錄

額外的準則：leader 不能直接複製或 commit 舊任期的紀錄
  [Figure 8 範例]
  任期 2 ，S1 無法複製紀錄給多數節點，然後 S1 失效
  任期 3 ，S5 成為 leader，增加一些紀錄，但也無法複製紀錄
  S1 復原，再次成為 leader
    開始處理任期 2 的舊紀錄，嘗試要求其他 follower 跟隨他的 log
    當任期 2 的紀錄順利複製到多數節點上後，我們是否允許這些 commit？
  答案是 no! 考慮下列情形：
    任期 2 的紀錄複製到 S3
    由於取得多數，S1 要 commit
    S1 再次失效
    任期 4 的選舉 S5 當選，S5 上最後的 log 是任期 3 (有任期 3 的 log 才能選任期 4)
    每個只有任期 2 log 的節點都會投票給 S5
  S5 成為 leader，試圖要求其他節點接受他的 log （任期 3 的紀錄）
    任期 2 的 index 2 會被這筆資料複寫
    但任期 2 的資料原本應當要被 S1 commit!
    這點違反 Leader 的資料完整性（Leader Completeness）原則
  解法：需要等待 S1 (前任 leader)也複製並 commit 任期 4 的紀錄
    確保 S5 不會在 S1 失效後不會當選（S5 缺乏任期 2 的紀錄）
    所以現在 commit 任期 2 的紀錄是安全的

Raft 何時可以合法複寫 log 紀錄？（cf. Figure 7 問題）
  被覆寫的紀錄必須尚未 commit
  可能截頭去尾，複寫一個較長的 log
    Figure 7 (f) 是一個有效範例
  e.g. 一個 leader 增加很多紀錄，但無法順利複製 log
    也許因為網路分割
  之後任期的其他的 leader 增加 log 紀錄到相同的索引（incices) (Fig 7 (a)-(e)）
    然後 commit 其中一部份
    現在就無法再次改變 log 索引的
  落後的節點稍後收到 AppendEntries，複寫尚未 commit 的紀錄
    就算前任 leader 上面的 uncommited log 比現任 leader 長
  這是安全的，因為節點在紀錄 commit 之後才會回覆客戶端
    所以 log 被新任 leader 複寫的前任 leader 節點，不會有機會回覆客戶端

*** 附錄: lab 2 Raft interface

  rf.Start(command) (index, term, isleader)
    Lab 3 k/v server 的 Put()/Get() RPC handler call Start()
    在下個 log 紀錄會開啟 Raft agreement
    Start() 立刻 return -- RPC handler 會等待 commit
    commit 前都有可能不成功，如果伺服器過程中失去 leadership
    isleader: 如果當前 server 不是 leader，告訴客戶端嘗試另外的 server
    term: currentTerm，幫助 caller 判對現在的 leader 是否超出任期
    index: 檢查 log entry ，判斷指令是否已經 commit
  應用 index 與指令
    Raft 傳送每個 committed log 訊息到 "apply channel"
    服務開始執行
    leader 使用 ApplyMsg 來判斷何時要回覆等待中的 RPC 客戶端

*** addendum: lab 2 Raft interface

  rf.Start(command) (index, term, isleader)
    Lab 3 k/v server's Put()/Get() RPC handlers call Start()
    start Raft agreement on a new log entry
    Start() returns immediately -- RPC handler must then wait for commit
    might not succeed if server loses leadership before committing command
    isleader: false if this server isn't the Raft leader, client should try another
    term: currentTerm, to help caller detect if leader is demoted
    index: log entry to watch to see if the command was committed
  ApplyMsg, with Index and Command
    Raft sends a message on the "apply channel" for each
    committed log entry. the service then knows to execute the
    command, and the leader uses the ApplyMsg
    to know when/what to reply to a waiting client RPC.
